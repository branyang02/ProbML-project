{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "CACHE_DIR = f\"/scratch/{os.getenv('USER')}/huggingface_cache\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect LM hidden states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6954051492da49ac9ad68cce2813ebf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "torch.random.manual_seed(0)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Phi-3-mini-4k-instruct\", \n",
    "    device_map=\"cuda\", \n",
    "    torch_dtype=\"auto\", \n",
    "    trust_remote_code=True, \n",
    "    cache_dir=CACHE_DIR\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\", cache_dir=CACHE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Phi3ForCausalLM(\n",
       "  (model): Phi3Model(\n",
       "    (embed_tokens): Embedding(32064, 3072, padding_idx=32000)\n",
       "    (embed_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x Phi3DecoderLayer(\n",
       "        (self_attn): Phi3Attention(\n",
       "          (o_proj): Linear(in_features=3072, out_features=3072, bias=False)\n",
       "          (qkv_proj): Linear(in_features=3072, out_features=9216, bias=False)\n",
       "          (rotary_emb): Phi3RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Phi3MLP(\n",
       "          (gate_up_proj): Linear(in_features=3072, out_features=16384, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=3072, bias=False)\n",
       "          (activation_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Phi3RMSNorm()\n",
       "        (resid_attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (resid_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (post_attention_layernorm): Phi3RMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): Phi3RMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=3072, out_features=32064, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.pipelines.text_generation import TextGenerationPipeline, ReturnType\n",
    "import numpy as np\n",
    "\n",
    "class CustomPipeline(TextGenerationPipeline):\n",
    "    \n",
    "    def _forward(self, model_inputs, **generate_kwargs):\n",
    "        input_ids = model_inputs[\"input_ids\"]\n",
    "        attention_mask = model_inputs.get(\"attention_mask\", None)\n",
    "        # Allow empty prompts\n",
    "        if input_ids.shape[1] == 0:\n",
    "            input_ids = None\n",
    "            attention_mask = None\n",
    "            in_b = 1\n",
    "        else:\n",
    "            in_b = input_ids.shape[0]\n",
    "        prompt_text = model_inputs.pop(\"prompt_text\")\n",
    "\n",
    "        # If there is a prefix, we may need to adjust the generation length. Do so without permanently modifying\n",
    "        # generate_kwargs, as some of the parameterization may come from the initialization of the pipeline.\n",
    "        prefix_length = generate_kwargs.pop(\"prefix_length\", 0)\n",
    "        if prefix_length > 0:\n",
    "            has_max_new_tokens = \"max_new_tokens\" in generate_kwargs or (\n",
    "                \"generation_config\" in generate_kwargs\n",
    "                and generate_kwargs[\"generation_config\"].max_new_tokens is not None\n",
    "            )\n",
    "            if not has_max_new_tokens:\n",
    "                generate_kwargs[\"max_length\"] = generate_kwargs.get(\"max_length\") or self.model.config.max_length\n",
    "                generate_kwargs[\"max_length\"] += prefix_length\n",
    "            has_min_new_tokens = \"min_new_tokens\" in generate_kwargs or (\n",
    "                \"generation_config\" in generate_kwargs\n",
    "                and generate_kwargs[\"generation_config\"].min_new_tokens is not None\n",
    "            )\n",
    "            if not has_min_new_tokens and \"min_length\" in generate_kwargs:\n",
    "                generate_kwargs[\"min_length\"] += prefix_length\n",
    "\n",
    "        # BS x SL\n",
    "        outputs = self.model.generate(input_ids=input_ids, attention_mask=attention_mask, return_dict_in_generate=True, **generate_kwargs)\n",
    "\n",
    "        n_layers = len(outputs.hidden_states[0][1:])\n",
    "        n_tokens = len(outputs.hidden_states[0][0][0, :, 0])\n",
    "        data = np.full((n_tokens, n_layers), None, dtype=object)         \n",
    "\n",
    "        for i, layer_hidden_state in enumerate(outputs.hidden_states[0]):\n",
    "            if i == 0:  # skip the embedding layer\n",
    "                continue\n",
    "            for j in range(n_tokens):\n",
    "                data[j, i-1] = layer_hidden_state[0, j, :].to(torch.float16).detach().cpu().numpy()\n",
    "\n",
    "        generated_sequence = outputs.sequences\n",
    "        \n",
    "        out_b = generated_sequence.shape[0]\n",
    "        if self.framework == \"pt\":\n",
    "            generated_sequence = generated_sequence.reshape(in_b, out_b // in_b, *generated_sequence.shape[1:])\n",
    "        elif self.framework == \"tf\":\n",
    "            generated_sequence = tf.reshape(generated_sequence, (in_b, out_b // in_b, *generated_sequence.shape[1:]))\n",
    "        return {\"generated_sequence\": generated_sequence, \"input_ids\": input_ids, \"prompt_text\": prompt_text, \"hidden_states\": data}\n",
    "\n",
    "    def postprocess(self, model_outputs, return_type=ReturnType.FULL_TEXT, clean_up_tokenization_spaces=True):\n",
    "        \n",
    "        # compute the raw decoded tokens in string format\n",
    "        generated_sequence = model_outputs['generated_sequence'][0,0,:]\n",
    "        tokens = [tokenizer.decode([token_id], skip_special_tokens=False, clean_up_tokenization_spaces=False) for token_id in generated_sequence]\n",
    "\n",
    "        result = super().postprocess(model_outputs, return_type, clean_up_tokenization_spaces)\n",
    "        result.append({\"tokens\": tokens})\n",
    "        result.append({\"hidden_states\": model_outputs[\"hidden_states\"]})\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Input:  ['The', 'University', 'of', 'Virginia', 'is', 'located', 'in', 'the', 'city', 'of']\n",
      "Tokenized Output:  ['The', 'University', 'of', 'Virginia', 'is', 'located', 'in', 'the', 'city', 'of', 'Char']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jqm9ba/.conda/envs/nlp/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer 1</th>\n",
       "      <th>layer 2</th>\n",
       "      <th>layer 3</th>\n",
       "      <th>layer 4</th>\n",
       "      <th>layer 5</th>\n",
       "      <th>layer 6</th>\n",
       "      <th>layer 7</th>\n",
       "      <th>layer 8</th>\n",
       "      <th>layer 9</th>\n",
       "      <th>layer 10</th>\n",
       "      <th>...</th>\n",
       "      <th>layer 23</th>\n",
       "      <th>layer 24</th>\n",
       "      <th>layer 25</th>\n",
       "      <th>layer 26</th>\n",
       "      <th>layer 27</th>\n",
       "      <th>layer 28</th>\n",
       "      <th>layer 29</th>\n",
       "      <th>layer 30</th>\n",
       "      <th>layer 31</th>\n",
       "      <th>layer 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>The</th>\n",
       "      <td>[0.02136, 0.03955, -0.006287, -0.1289, 0.02893...</td>\n",
       "      <td>[0.06055, -0.003418, 0.02124, -0.1816, 0.05225...</td>\n",
       "      <td>[0.0327, -0.1953, -0.03125, -0.3633, -0.1504, ...</td>\n",
       "      <td>[0.04907, -0.1768, -0.031, -0.3281, -0.2695, -...</td>\n",
       "      <td>[0.801, -0.3047, -0.05664, 0.1543, -1.055, 0.3...</td>\n",
       "      <td>[0.8555, -0.2598, -0.03467, 0.1758, -1.047, 0....</td>\n",
       "      <td>[0.824, -0.379, -0.0752, 0.3672, -0.8438, 0.61...</td>\n",
       "      <td>[1.406, -0.707, -0.03027, 0.2432, -1.484, 0.12...</td>\n",
       "      <td>[1.4375, -0.7656, 0.0249, 0.249, -1.4375, 0.15...</td>\n",
       "      <td>[1.469, -0.6094, 0.0679, 0.2695, -1.414, 0.174...</td>\n",
       "      <td>...</td>\n",
       "      <td>[1.008, -1.828, 0.9062, 0.04053, -1.75, 1.125,...</td>\n",
       "      <td>[1.047, -2.078, 1.1875, 0.1357, -1.5625, 1.055...</td>\n",
       "      <td>[1.141, -2.14, 1.32, 0.3809, -1.586, 1.016, 0....</td>\n",
       "      <td>[1.3125, -2.344, 1.625, 0.5664, -1.422, 0.953,...</td>\n",
       "      <td>[1.18, -2.312, 1.844, 0.582, -1.1875, 0.957, 0...</td>\n",
       "      <td>[0.9453, -2.172, 1.602, 0.1797, -1.219, 0.664,...</td>\n",
       "      <td>[1.445, -2.516, 2.5, 0.2832, -1.633, 0.3867, 0...</td>\n",
       "      <td>[1.016, -0.75, 0.711, -1.094, 0.2422, 0.1309, ...</td>\n",
       "      <td>[1.32, -0.879, 1.953, -0.711, -0.7734, 0.1289,...</td>\n",
       "      <td>[-0.3477, 0.3184, -0.1426, -0.0996, 0.3828, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>University</th>\n",
       "      <td>[-0.02417, -0.006836, -0.01794, 0.08594, 0.038...</td>\n",
       "      <td>[0.012695, -0.0349, -0.0547, 0.1406, 0.1768, -...</td>\n",
       "      <td>[0.04834, 0.09766, 0.01196, 0.2344, 0.1963, -0...</td>\n",
       "      <td>[0.1484, 0.1553, 0.04785, 0.3828, 0.3516, -0.1...</td>\n",
       "      <td>[0.1836, 0.371, 0.01648, 0.3828, 0.25, -0.1631...</td>\n",
       "      <td>[0.2295, 0.377, -0.007324, 0.4492, 0.1797, -0....</td>\n",
       "      <td>[0.336, 0.457, -0.0381, 0.1562, 0.09375, 0.041...</td>\n",
       "      <td>[0.4395, 0.457, -0.04248, 0.21, -0.1523, -0.05...</td>\n",
       "      <td>[0.4492, 0.5625, -0.0713, 0.05273, -0.1875, 0....</td>\n",
       "      <td>[0.1582, 0.7812, -0.04395, 0.1709, -0.012695, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[1.102, 3.25, -4.156, 1.242, -0.617, -0.2207, ...</td>\n",
       "      <td>[0.926, 3.453, -5.156, 2.75, 0.2852, -0.3281, ...</td>\n",
       "      <td>[1.016, 3.812, -5.594, 2.719, -0.498, 0.7188, ...</td>\n",
       "      <td>[1.078, 2.672, -7.22, 4.22, -0.547, 1.023, 0.0...</td>\n",
       "      <td>[1.57, 3.094, -7.562, 4.875, -0.02734, 0.1953,...</td>\n",
       "      <td>[-0.0625, 3.312, -8.56, 6.688, -0.4805, 1.266,...</td>\n",
       "      <td>[-0.3066, 1.078, -7.03, 7.094, -0.1895, 0.2578...</td>\n",
       "      <td>[-0.5195, 2.062, -5.78, 7.406, -1.086, 1.078, ...</td>\n",
       "      <td>[-1.055, 2.938, -5.97, 7.875, 0.5703, 2.672, -...</td>\n",
       "      <td>[-0.5195, 0.832, -1.094, 2.375, 0.4434, 0.715,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>[-0.03857, 0.0415, 0.04834, -0.01477, -0.00015...</td>\n",
       "      <td>[-0.0664, 0.0698, 0.04932, -0.02173, 0.03516, ...</td>\n",
       "      <td>[0.06128, -0.02832, -0.1138, -0.02893, 0.01147...</td>\n",
       "      <td>[0.06055, 0.0376, -0.582, -0.3125, 0.06226, -0...</td>\n",
       "      <td>[0.09766, 0.2207, -0.6055, -0.4883, 0.08203, -...</td>\n",
       "      <td>[0.0952, 0.5312, -0.6406, -0.789, 0.01343, 0.1...</td>\n",
       "      <td>[0.455, 0.6953, -0.996, -0.824, -0.1846, 0.034...</td>\n",
       "      <td>[0.3145, 0.9297, -1.203, -0.66, -0.1465, 0.089...</td>\n",
       "      <td>[0.3633, 1.328, -1.0, -0.625, -0.2461, 0.3457,...</td>\n",
       "      <td>[0.3867, 1.5625, -1.281, -0.4766, -0.1533, 0.2...</td>\n",
       "      <td>...</td>\n",
       "      <td>[-1.336, 2.969, -3.14, 1.078, 0.2344, -1.148, ...</td>\n",
       "      <td>[-0.9297, 3.562, -3.875, 1.055, 0.04102, -1.12...</td>\n",
       "      <td>[-0.8203, 4.344, -4.625, 1.547, 0.3633, -1.141...</td>\n",
       "      <td>[0.1797, 4.938, -4.78, 1.43, 0.0371, -1.109, 0...</td>\n",
       "      <td>[0.295, 5.188, -5.125, 2.312, -0.535, -2.234, ...</td>\n",
       "      <td>[-0.1875, 3.719, -5.47, 2.062, -1.148, -2.36, ...</td>\n",
       "      <td>[1.3125, 3.625, -5.25, 3.266, 0.3672, -4.188, ...</td>\n",
       "      <td>[1.508, 4.688, -4.03, 5.188, -0.1758, -2.766, ...</td>\n",
       "      <td>[0.7617, 4.688, -1.719, 4.72, -0.463, -1.945, ...</td>\n",
       "      <td>[-0.4727, 0.9688, -0.3203, 0.9688, 0.59, -0.10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Virginia</th>\n",
       "      <td>[-0.0703, 0.04712, -0.02466, 0.10986, 0.0884, ...</td>\n",
       "      <td>[-0.007812, 0.052, -0.013306, 0.1221, 0.06885,...</td>\n",
       "      <td>[-0.00482, 0.00598, -0.103, 0.1953, 0.04736, -...</td>\n",
       "      <td>[0.05176, -0.1406, -0.04395, 0.2217, -0.0762, ...</td>\n",
       "      <td>[-0.01953, -0.0879, -0.2012, 0.08887, -0.08496...</td>\n",
       "      <td>[0.3086, 0.2197, 0.0, 0.062, -0.336, 0.455, -0...</td>\n",
       "      <td>[0.824, 0.3242, 0.07715, 0.1914, -0.04297, 0.4...</td>\n",
       "      <td>[0.676, 0.4844, -0.1177, 0.375, -0.1445, 0.515...</td>\n",
       "      <td>[0.6406, 0.6094, -0.254, 0.4043, 0.04736, 0.38...</td>\n",
       "      <td>[0.832, 1.047, -0.91, 0.4766, -0.02075, 0.5117...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.664, 2.875, -2.5, -2.438, 1.672, -0.2227, -...</td>\n",
       "      <td>[2.344, 2.188, -1.867, -1.1875, 2.125, -0.2383...</td>\n",
       "      <td>[1.703, 1.547, -2.812, -1.156, 1.8125, 1.734, ...</td>\n",
       "      <td>[2.375, 0.3105, -5.125, -2.078, 3.688, 1.594, ...</td>\n",
       "      <td>[4.78, -0.01074, -4.156, -2.375, 4.812, 1.07, ...</td>\n",
       "      <td>[3.562, -0.8125, -6.0, -0.9062, 3.578, 1.117, ...</td>\n",
       "      <td>[4.625, -0.01074, -5.438, -1.398, 2.75, -0.240...</td>\n",
       "      <td>[6.375, -0.007812, -6.03, -3.25, 2.094, 0.0468...</td>\n",
       "      <td>[6.344, 2.375, -6.344, -3.312, 2.922, 1.297, -...</td>\n",
       "      <td>[0.3965, 1.039, -0.6836, -0.2617, 0.9844, 0.30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>[-0.010254, -0.00775, -0.002502, 0.01428, -0.0...</td>\n",
       "      <td>[-0.006226, 0.001709, 0.001099, 0.02563, -0.07...</td>\n",
       "      <td>[-0.0188, 0.0703, -0.0177, 0.02393, -0.1079, -...</td>\n",
       "      <td>[0.001617, 0.1211, -0.0947, -0.04492, -0.0327,...</td>\n",
       "      <td>[0.01587, 0.3281, -0.1416, -0.04834, -0.03564,...</td>\n",
       "      <td>[-0.1797, 0.375, -0.3516, 0.003906, -0.1001, -...</td>\n",
       "      <td>[-0.1172, 0.4355, -0.379, 0.0537, -0.1328, -0....</td>\n",
       "      <td>[0.03125, 0.4844, -0.418, 0.1758, -0.08203, 0....</td>\n",
       "      <td>[0.01514, 0.5703, -0.3145, 0.1035, -0.1084, -0...</td>\n",
       "      <td>[-0.1436, 0.871, -0.2275, 0.336, -0.0908, -0.0...</td>\n",
       "      <td>...</td>\n",
       "      <td>[-2.016, -1.32, -4.375, 1.422, 3.469, -0.0654,...</td>\n",
       "      <td>[-1.844, -1.164, -2.969, 2.188, 6.125, 1.141, ...</td>\n",
       "      <td>[-2.922, -1.07, -2.953, 2.078, 6.906, 1.016, -...</td>\n",
       "      <td>[-1.609, -0.758, -4.0, 2.656, 8.625, 2.219, -1...</td>\n",
       "      <td>[-2.594, 2.156, -5.5, 4.562, 8.375, 1.695, 0.1...</td>\n",
       "      <td>[-3.61, 2.0, -8.125, 5.062, 8.69, 2.5, -1.094,...</td>\n",
       "      <td>[-3.375, 3.828, -8.19, 5.312, 8.81, 2.578, -4....</td>\n",
       "      <td>[-1.836, 5.25, -10.56, 5.562, 8.31, 4.125, -1....</td>\n",
       "      <td>[-1.766, 8.06, -9.56, 6.812, 8.19, 4.938, -3.2...</td>\n",
       "      <td>[-0.668, 2.36, -1.227, 1.469, 2.0, 1.133, -1.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>located</th>\n",
       "      <td>[0.03174, -0.0564, -0.02771, -0.0293, -0.04395...</td>\n",
       "      <td>[0.1533, -0.09766, 0.03687, -0.0337, -0.0304, ...</td>\n",
       "      <td>[0.167, -0.207, -0.0928, -0.02856, -0.05664, -...</td>\n",
       "      <td>[0.206, -0.02441, -0.1396, -0.08057, -0.0757, ...</td>\n",
       "      <td>[0.3418, 0.083, -0.3203, -0.254, -0.0442, -0.1...</td>\n",
       "      <td>[0.2988, 0.0432, -0.4512, -0.4844, -0.05493, 0...</td>\n",
       "      <td>[0.04883, 0.1719, -0.3809, -0.6016, -0.166, -0...</td>\n",
       "      <td>[0.1445, 0.11035, -0.3477, -0.4336, 0.2578, -0...</td>\n",
       "      <td>[-0.166, 0.3516, -0.3691, -0.463, 0.12305, -0....</td>\n",
       "      <td>[-0.0698, 0.4297, -0.336, -0.3184, 0.05957, -0...</td>\n",
       "      <td>...</td>\n",
       "      <td>[-1.375, -3.14, -0.8125, -3.328, -0.961, -0.80...</td>\n",
       "      <td>[0.2344, -3.266, 1.023, -1.641, -0.10547, -1.8...</td>\n",
       "      <td>[0.8984, -3.75, -1.375, -1.008, 0.7344, -0.976...</td>\n",
       "      <td>[0.8984, -4.156, -2.531, -0.715, 0.498, -1.148...</td>\n",
       "      <td>[0.9336, -3.438, -1.516, 0.3555, -0.1211, -1.7...</td>\n",
       "      <td>[-0.824, -0.953, -1.969, 0.789, 0.1001, -1.703...</td>\n",
       "      <td>[-2.156, -1.469, -1.461, 1.797, 1.1875, -1.023...</td>\n",
       "      <td>[-2.406, 1.5625, -0.9297, 0.1094, 1.047, -1.28...</td>\n",
       "      <td>[-4.375, 3.688, -0.617, 4.125, -0.2812, 1.891,...</td>\n",
       "      <td>[-1.156, 1.586, -0.2148, 1.586, 0.789, 1.156, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>[0.0454, -0.01855, 0.010254, -0.02515, -0.0086...</td>\n",
       "      <td>[0.0515, 0.00641, 0.03613, -0.00842, -0.01746,...</td>\n",
       "      <td>[0.0762, 0.05908, 0.05176, -0.0332, -0.02039, ...</td>\n",
       "      <td>[0.05078, 0.1904, -0.02832, -0.06445, -0.0869,...</td>\n",
       "      <td>[0.1973, 0.2344, -0.05225, -0.1523, -0.11426, ...</td>\n",
       "      <td>[0.3027, 0.10986, -0.1748, -0.2441, -0.1084, -...</td>\n",
       "      <td>[0.1216, 0.04053, -0.05225, -0.3887, -0.1768, ...</td>\n",
       "      <td>[0.25, 0.0996, -0.2324, -0.04883, -0.105, -0.4...</td>\n",
       "      <td>[-0.1309, 0.0371, -0.3848, -0.3828, 0.06396, -...</td>\n",
       "      <td>[-0.2285, -0.1318, -0.08203, -0.127, -0.3223, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[-3.406, -1.953, -2.5, -1.516, -2.156, -0.9062...</td>\n",
       "      <td>[-3.531, -3.11, 2.5, 1.07, -1.18, -1.289, -4.5...</td>\n",
       "      <td>[-0.4375, -1.992, 3.688, 4.75, 2.828, 1.195, -...</td>\n",
       "      <td>[0.625, -3.188, 2.703, 6.0, 3.375, -2.219, -5....</td>\n",
       "      <td>[2.11, -3.312, 4.688, 7.812, 2.703, -1.211, -4...</td>\n",
       "      <td>[0.4688, -4.75, 4.344, 8.19, 2.547, -2.656, -6...</td>\n",
       "      <td>[0.7656, -4.22, 7.156, 8.94, 3.062, -4.5, -12....</td>\n",
       "      <td>[0.789, -5.156, 9.44, 9.69, 2.078, -3.312, -11...</td>\n",
       "      <td>[2.203, -3.594, 8.94, 10.125, 2.812, -1.477, -...</td>\n",
       "      <td>[0.00958, -0.004883, 1.258, 2.125, 1.258, 0.57...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>[0.03516, -0.02112, 0.003479, -0.04175, 0.0434...</td>\n",
       "      <td>[-0.003906, 0.01459, 0.04395, 0.021, -0.0188, ...</td>\n",
       "      <td>[-0.02881, 0.004395, 0.012146, -0.00769, -0.00...</td>\n",
       "      <td>[-0.03906, 0.01794, 0.01526, -0.01196, -0.0156...</td>\n",
       "      <td>[-0.02026, 0.003662, -0.0004272, -0.02759, -0....</td>\n",
       "      <td>[0.003418, 0.02026, 0.02612, -0.0349, -0.08545...</td>\n",
       "      <td>[0.0359, 0.06396, 0.1289, -0.1245, -0.3672, -0...</td>\n",
       "      <td>[-0.009766, 0.2148, -0.1992, -0.083, 0.03125, ...</td>\n",
       "      <td>[-0.3887, 0.2324, -0.0908, -0.375, 0.06934, -0...</td>\n",
       "      <td>[-0.3203, 0.10645, 0.09375, -0.1387, -0.02246,...</td>\n",
       "      <td>...</td>\n",
       "      <td>[-2.672, -3.0, 0.547, -3.078, -1.625, -1.086, ...</td>\n",
       "      <td>[-1.117, -3.14, 3.766, -2.188, 0.08594, -1.992...</td>\n",
       "      <td>[-0.3125, -4.28, 4.156, -0.6953, 1.3125, -1.41...</td>\n",
       "      <td>[0.5312, -6.125, 2.781, -0.547, 3.656, -4.438,...</td>\n",
       "      <td>[2.656, -5.656, 3.594, -0.871, 2.703, -5.25, -...</td>\n",
       "      <td>[3.5, -5.812, 2.062, -1.094, 2.0, -4.375, -8.1...</td>\n",
       "      <td>[4.344, -3.016, 2.188, -2.453, 0.0547, -2.438,...</td>\n",
       "      <td>[6.312, -0.8047, 2.812, -2.438, -1.4375, -2.73...</td>\n",
       "      <td>[7.375, -2.25, 4.03, -0.953, 1.992, -1.445, -9...</td>\n",
       "      <td>[0.793, 0.4043, 0.5938, 0.867, 1.43, 0.1963, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <td>[-0.01965, 0.08545, 0.02417, 0.02551, 0.02856,...</td>\n",
       "      <td>[-0.0503, 0.0879, 0.04224, 0.0398, 0.01404, -0...</td>\n",
       "      <td>[-0.083, 0.1001, 0.06104, 0.0884, 0.04468, -0....</td>\n",
       "      <td>[-0.06152, 0.05615, 0.1387, 0.05615, 0.0996, -...</td>\n",
       "      <td>[0.02576, 0.1328, 0.1465, 0.001953, 0.1289, -0...</td>\n",
       "      <td>[-0.012085, 0.1562, 0.166, -0.0542, 0.03564, -...</td>\n",
       "      <td>[-0.3828, 0.2129, 0.07324, -0.1514, -0.08984, ...</td>\n",
       "      <td>[-0.547, 0.3281, 0.11523, -0.08496, 0.0635, -0...</td>\n",
       "      <td>[-0.4863, 0.3125, 0.3203, -0.0923, 0.0713, -0....</td>\n",
       "      <td>[-0.625, 0.508, 0.3984, -0.1729, 0.0757, -0.25...</td>\n",
       "      <td>...</td>\n",
       "      <td>[-1.969, -0.59, -3.969, -1.633, 0.7188, -2.594...</td>\n",
       "      <td>[-3.203, 0.25, -3.844, 0.0625, 1.9375, -3.562,...</td>\n",
       "      <td>[-2.14, -0.2988, -3.406, 0.914, 2.781, -2.938,...</td>\n",
       "      <td>[-1.719, -1.609, -4.188, 0.3516, 2.281, -3.64,...</td>\n",
       "      <td>[-2.11, -0.914, -5.344, 0.291, 2.812, -5.0, -3...</td>\n",
       "      <td>[-1.672, -0.379, -4.875, -0.1914, 3.453, -4.78...</td>\n",
       "      <td>[-3.312, -0.633, -5.438, -1.07, 1.9375, -4.0, ...</td>\n",
       "      <td>[-1.625, 0.7227, -6.156, -0.06055, 2.734, -1.1...</td>\n",
       "      <td>[-1.047, -0.6914, -5.375, 3.156, 3.938, 0.1484...</td>\n",
       "      <td>[-0.7383, 0.547, -0.824, 1.164, 1.625, 0.498, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>[-0.02661, 0.021, 0.02722, -0.00818, 0.01196, ...</td>\n",
       "      <td>[-0.007446, 0.02148, 0.0315, 0.000977, -0.0105...</td>\n",
       "      <td>[0.0166, 0.01257, -0.03784, -0.00806, 0.1201, ...</td>\n",
       "      <td>[-0.0437, 0.1289, -0.0801, -0.04053, 0.01709, ...</td>\n",
       "      <td>[0.2031, 0.2676, 0.02881, -0.1377, 0.3594, -0....</td>\n",
       "      <td>[0.10205, 0.5273, -0.2266, 0.02832, 0.1367, -0...</td>\n",
       "      <td>[0.02698, 0.715, -0.3613, 0.03955, -0.0752, -0...</td>\n",
       "      <td>[-0.1543, 0.8047, -0.5703, -0.08496, 0.1953, -...</td>\n",
       "      <td>[-0.2676, 0.7773, -0.461, 0.01953, 0.1504, -0....</td>\n",
       "      <td>[-0.6797, 0.6562, -0.508, 0.06152, -0.11816, -...</td>\n",
       "      <td>...</td>\n",
       "      <td>[-1.9375, -2.406, -1.984, -1.125, -2.547, -0.5...</td>\n",
       "      <td>[-1.664, -3.86, 3.188, 1.656, -1.266, -1.031, ...</td>\n",
       "      <td>[1.422, -2.688, 4.188, 5.938, 3.531, 0.75, -3....</td>\n",
       "      <td>[2.375, -3.844, 3.516, 7.688, 3.953, -2.719, -...</td>\n",
       "      <td>[4.75, -4.812, 6.062, 10.25, 3.156, -2.906, -4...</td>\n",
       "      <td>[3.36, -5.938, 5.75, 11.56, 2.062, -3.016, -5....</td>\n",
       "      <td>[3.36, -5.188, 7.938, 11.31, 2.719, -5.938, -1...</td>\n",
       "      <td>[3.062, -6.312, 10.625, 11.69, 1.93, -5.688, -...</td>\n",
       "      <td>[4.312, -5.812, 9.69, 12.19, 3.484, -5.125, -1...</td>\n",
       "      <td>[0.9062, -1.289, 1.8125, 3.031, 1.156, -0.2793...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      layer 1  \\\n",
       "The         [0.02136, 0.03955, -0.006287, -0.1289, 0.02893...   \n",
       "University  [-0.02417, -0.006836, -0.01794, 0.08594, 0.038...   \n",
       "of          [-0.03857, 0.0415, 0.04834, -0.01477, -0.00015...   \n",
       "Virginia    [-0.0703, 0.04712, -0.02466, 0.10986, 0.0884, ...   \n",
       "is          [-0.010254, -0.00775, -0.002502, 0.01428, -0.0...   \n",
       "located     [0.03174, -0.0564, -0.02771, -0.0293, -0.04395...   \n",
       "in          [0.0454, -0.01855, 0.010254, -0.02515, -0.0086...   \n",
       "the         [0.03516, -0.02112, 0.003479, -0.04175, 0.0434...   \n",
       "city        [-0.01965, 0.08545, 0.02417, 0.02551, 0.02856,...   \n",
       "of          [-0.02661, 0.021, 0.02722, -0.00818, 0.01196, ...   \n",
       "\n",
       "                                                      layer 2  \\\n",
       "The         [0.06055, -0.003418, 0.02124, -0.1816, 0.05225...   \n",
       "University  [0.012695, -0.0349, -0.0547, 0.1406, 0.1768, -...   \n",
       "of          [-0.0664, 0.0698, 0.04932, -0.02173, 0.03516, ...   \n",
       "Virginia    [-0.007812, 0.052, -0.013306, 0.1221, 0.06885,...   \n",
       "is          [-0.006226, 0.001709, 0.001099, 0.02563, -0.07...   \n",
       "located     [0.1533, -0.09766, 0.03687, -0.0337, -0.0304, ...   \n",
       "in          [0.0515, 0.00641, 0.03613, -0.00842, -0.01746,...   \n",
       "the         [-0.003906, 0.01459, 0.04395, 0.021, -0.0188, ...   \n",
       "city        [-0.0503, 0.0879, 0.04224, 0.0398, 0.01404, -0...   \n",
       "of          [-0.007446, 0.02148, 0.0315, 0.000977, -0.0105...   \n",
       "\n",
       "                                                      layer 3  \\\n",
       "The         [0.0327, -0.1953, -0.03125, -0.3633, -0.1504, ...   \n",
       "University  [0.04834, 0.09766, 0.01196, 0.2344, 0.1963, -0...   \n",
       "of          [0.06128, -0.02832, -0.1138, -0.02893, 0.01147...   \n",
       "Virginia    [-0.00482, 0.00598, -0.103, 0.1953, 0.04736, -...   \n",
       "is          [-0.0188, 0.0703, -0.0177, 0.02393, -0.1079, -...   \n",
       "located     [0.167, -0.207, -0.0928, -0.02856, -0.05664, -...   \n",
       "in          [0.0762, 0.05908, 0.05176, -0.0332, -0.02039, ...   \n",
       "the         [-0.02881, 0.004395, 0.012146, -0.00769, -0.00...   \n",
       "city        [-0.083, 0.1001, 0.06104, 0.0884, 0.04468, -0....   \n",
       "of          [0.0166, 0.01257, -0.03784, -0.00806, 0.1201, ...   \n",
       "\n",
       "                                                      layer 4  \\\n",
       "The         [0.04907, -0.1768, -0.031, -0.3281, -0.2695, -...   \n",
       "University  [0.1484, 0.1553, 0.04785, 0.3828, 0.3516, -0.1...   \n",
       "of          [0.06055, 0.0376, -0.582, -0.3125, 0.06226, -0...   \n",
       "Virginia    [0.05176, -0.1406, -0.04395, 0.2217, -0.0762, ...   \n",
       "is          [0.001617, 0.1211, -0.0947, -0.04492, -0.0327,...   \n",
       "located     [0.206, -0.02441, -0.1396, -0.08057, -0.0757, ...   \n",
       "in          [0.05078, 0.1904, -0.02832, -0.06445, -0.0869,...   \n",
       "the         [-0.03906, 0.01794, 0.01526, -0.01196, -0.0156...   \n",
       "city        [-0.06152, 0.05615, 0.1387, 0.05615, 0.0996, -...   \n",
       "of          [-0.0437, 0.1289, -0.0801, -0.04053, 0.01709, ...   \n",
       "\n",
       "                                                      layer 5  \\\n",
       "The         [0.801, -0.3047, -0.05664, 0.1543, -1.055, 0.3...   \n",
       "University  [0.1836, 0.371, 0.01648, 0.3828, 0.25, -0.1631...   \n",
       "of          [0.09766, 0.2207, -0.6055, -0.4883, 0.08203, -...   \n",
       "Virginia    [-0.01953, -0.0879, -0.2012, 0.08887, -0.08496...   \n",
       "is          [0.01587, 0.3281, -0.1416, -0.04834, -0.03564,...   \n",
       "located     [0.3418, 0.083, -0.3203, -0.254, -0.0442, -0.1...   \n",
       "in          [0.1973, 0.2344, -0.05225, -0.1523, -0.11426, ...   \n",
       "the         [-0.02026, 0.003662, -0.0004272, -0.02759, -0....   \n",
       "city        [0.02576, 0.1328, 0.1465, 0.001953, 0.1289, -0...   \n",
       "of          [0.2031, 0.2676, 0.02881, -0.1377, 0.3594, -0....   \n",
       "\n",
       "                                                      layer 6  \\\n",
       "The         [0.8555, -0.2598, -0.03467, 0.1758, -1.047, 0....   \n",
       "University  [0.2295, 0.377, -0.007324, 0.4492, 0.1797, -0....   \n",
       "of          [0.0952, 0.5312, -0.6406, -0.789, 0.01343, 0.1...   \n",
       "Virginia    [0.3086, 0.2197, 0.0, 0.062, -0.336, 0.455, -0...   \n",
       "is          [-0.1797, 0.375, -0.3516, 0.003906, -0.1001, -...   \n",
       "located     [0.2988, 0.0432, -0.4512, -0.4844, -0.05493, 0...   \n",
       "in          [0.3027, 0.10986, -0.1748, -0.2441, -0.1084, -...   \n",
       "the         [0.003418, 0.02026, 0.02612, -0.0349, -0.08545...   \n",
       "city        [-0.012085, 0.1562, 0.166, -0.0542, 0.03564, -...   \n",
       "of          [0.10205, 0.5273, -0.2266, 0.02832, 0.1367, -0...   \n",
       "\n",
       "                                                      layer 7  \\\n",
       "The         [0.824, -0.379, -0.0752, 0.3672, -0.8438, 0.61...   \n",
       "University  [0.336, 0.457, -0.0381, 0.1562, 0.09375, 0.041...   \n",
       "of          [0.455, 0.6953, -0.996, -0.824, -0.1846, 0.034...   \n",
       "Virginia    [0.824, 0.3242, 0.07715, 0.1914, -0.04297, 0.4...   \n",
       "is          [-0.1172, 0.4355, -0.379, 0.0537, -0.1328, -0....   \n",
       "located     [0.04883, 0.1719, -0.3809, -0.6016, -0.166, -0...   \n",
       "in          [0.1216, 0.04053, -0.05225, -0.3887, -0.1768, ...   \n",
       "the         [0.0359, 0.06396, 0.1289, -0.1245, -0.3672, -0...   \n",
       "city        [-0.3828, 0.2129, 0.07324, -0.1514, -0.08984, ...   \n",
       "of          [0.02698, 0.715, -0.3613, 0.03955, -0.0752, -0...   \n",
       "\n",
       "                                                      layer 8  \\\n",
       "The         [1.406, -0.707, -0.03027, 0.2432, -1.484, 0.12...   \n",
       "University  [0.4395, 0.457, -0.04248, 0.21, -0.1523, -0.05...   \n",
       "of          [0.3145, 0.9297, -1.203, -0.66, -0.1465, 0.089...   \n",
       "Virginia    [0.676, 0.4844, -0.1177, 0.375, -0.1445, 0.515...   \n",
       "is          [0.03125, 0.4844, -0.418, 0.1758, -0.08203, 0....   \n",
       "located     [0.1445, 0.11035, -0.3477, -0.4336, 0.2578, -0...   \n",
       "in          [0.25, 0.0996, -0.2324, -0.04883, -0.105, -0.4...   \n",
       "the         [-0.009766, 0.2148, -0.1992, -0.083, 0.03125, ...   \n",
       "city        [-0.547, 0.3281, 0.11523, -0.08496, 0.0635, -0...   \n",
       "of          [-0.1543, 0.8047, -0.5703, -0.08496, 0.1953, -...   \n",
       "\n",
       "                                                      layer 9  \\\n",
       "The         [1.4375, -0.7656, 0.0249, 0.249, -1.4375, 0.15...   \n",
       "University  [0.4492, 0.5625, -0.0713, 0.05273, -0.1875, 0....   \n",
       "of          [0.3633, 1.328, -1.0, -0.625, -0.2461, 0.3457,...   \n",
       "Virginia    [0.6406, 0.6094, -0.254, 0.4043, 0.04736, 0.38...   \n",
       "is          [0.01514, 0.5703, -0.3145, 0.1035, -0.1084, -0...   \n",
       "located     [-0.166, 0.3516, -0.3691, -0.463, 0.12305, -0....   \n",
       "in          [-0.1309, 0.0371, -0.3848, -0.3828, 0.06396, -...   \n",
       "the         [-0.3887, 0.2324, -0.0908, -0.375, 0.06934, -0...   \n",
       "city        [-0.4863, 0.3125, 0.3203, -0.0923, 0.0713, -0....   \n",
       "of          [-0.2676, 0.7773, -0.461, 0.01953, 0.1504, -0....   \n",
       "\n",
       "                                                     layer 10  ...  \\\n",
       "The         [1.469, -0.6094, 0.0679, 0.2695, -1.414, 0.174...  ...   \n",
       "University  [0.1582, 0.7812, -0.04395, 0.1709, -0.012695, ...  ...   \n",
       "of          [0.3867, 1.5625, -1.281, -0.4766, -0.1533, 0.2...  ...   \n",
       "Virginia    [0.832, 1.047, -0.91, 0.4766, -0.02075, 0.5117...  ...   \n",
       "is          [-0.1436, 0.871, -0.2275, 0.336, -0.0908, -0.0...  ...   \n",
       "located     [-0.0698, 0.4297, -0.336, -0.3184, 0.05957, -0...  ...   \n",
       "in          [-0.2285, -0.1318, -0.08203, -0.127, -0.3223, ...  ...   \n",
       "the         [-0.3203, 0.10645, 0.09375, -0.1387, -0.02246,...  ...   \n",
       "city        [-0.625, 0.508, 0.3984, -0.1729, 0.0757, -0.25...  ...   \n",
       "of          [-0.6797, 0.6562, -0.508, 0.06152, -0.11816, -...  ...   \n",
       "\n",
       "                                                     layer 23  \\\n",
       "The         [1.008, -1.828, 0.9062, 0.04053, -1.75, 1.125,...   \n",
       "University  [1.102, 3.25, -4.156, 1.242, -0.617, -0.2207, ...   \n",
       "of          [-1.336, 2.969, -3.14, 1.078, 0.2344, -1.148, ...   \n",
       "Virginia    [0.664, 2.875, -2.5, -2.438, 1.672, -0.2227, -...   \n",
       "is          [-2.016, -1.32, -4.375, 1.422, 3.469, -0.0654,...   \n",
       "located     [-1.375, -3.14, -0.8125, -3.328, -0.961, -0.80...   \n",
       "in          [-3.406, -1.953, -2.5, -1.516, -2.156, -0.9062...   \n",
       "the         [-2.672, -3.0, 0.547, -3.078, -1.625, -1.086, ...   \n",
       "city        [-1.969, -0.59, -3.969, -1.633, 0.7188, -2.594...   \n",
       "of          [-1.9375, -2.406, -1.984, -1.125, -2.547, -0.5...   \n",
       "\n",
       "                                                     layer 24  \\\n",
       "The         [1.047, -2.078, 1.1875, 0.1357, -1.5625, 1.055...   \n",
       "University  [0.926, 3.453, -5.156, 2.75, 0.2852, -0.3281, ...   \n",
       "of          [-0.9297, 3.562, -3.875, 1.055, 0.04102, -1.12...   \n",
       "Virginia    [2.344, 2.188, -1.867, -1.1875, 2.125, -0.2383...   \n",
       "is          [-1.844, -1.164, -2.969, 2.188, 6.125, 1.141, ...   \n",
       "located     [0.2344, -3.266, 1.023, -1.641, -0.10547, -1.8...   \n",
       "in          [-3.531, -3.11, 2.5, 1.07, -1.18, -1.289, -4.5...   \n",
       "the         [-1.117, -3.14, 3.766, -2.188, 0.08594, -1.992...   \n",
       "city        [-3.203, 0.25, -3.844, 0.0625, 1.9375, -3.562,...   \n",
       "of          [-1.664, -3.86, 3.188, 1.656, -1.266, -1.031, ...   \n",
       "\n",
       "                                                     layer 25  \\\n",
       "The         [1.141, -2.14, 1.32, 0.3809, -1.586, 1.016, 0....   \n",
       "University  [1.016, 3.812, -5.594, 2.719, -0.498, 0.7188, ...   \n",
       "of          [-0.8203, 4.344, -4.625, 1.547, 0.3633, -1.141...   \n",
       "Virginia    [1.703, 1.547, -2.812, -1.156, 1.8125, 1.734, ...   \n",
       "is          [-2.922, -1.07, -2.953, 2.078, 6.906, 1.016, -...   \n",
       "located     [0.8984, -3.75, -1.375, -1.008, 0.7344, -0.976...   \n",
       "in          [-0.4375, -1.992, 3.688, 4.75, 2.828, 1.195, -...   \n",
       "the         [-0.3125, -4.28, 4.156, -0.6953, 1.3125, -1.41...   \n",
       "city        [-2.14, -0.2988, -3.406, 0.914, 2.781, -2.938,...   \n",
       "of          [1.422, -2.688, 4.188, 5.938, 3.531, 0.75, -3....   \n",
       "\n",
       "                                                     layer 26  \\\n",
       "The         [1.3125, -2.344, 1.625, 0.5664, -1.422, 0.953,...   \n",
       "University  [1.078, 2.672, -7.22, 4.22, -0.547, 1.023, 0.0...   \n",
       "of          [0.1797, 4.938, -4.78, 1.43, 0.0371, -1.109, 0...   \n",
       "Virginia    [2.375, 0.3105, -5.125, -2.078, 3.688, 1.594, ...   \n",
       "is          [-1.609, -0.758, -4.0, 2.656, 8.625, 2.219, -1...   \n",
       "located     [0.8984, -4.156, -2.531, -0.715, 0.498, -1.148...   \n",
       "in          [0.625, -3.188, 2.703, 6.0, 3.375, -2.219, -5....   \n",
       "the         [0.5312, -6.125, 2.781, -0.547, 3.656, -4.438,...   \n",
       "city        [-1.719, -1.609, -4.188, 0.3516, 2.281, -3.64,...   \n",
       "of          [2.375, -3.844, 3.516, 7.688, 3.953, -2.719, -...   \n",
       "\n",
       "                                                     layer 27  \\\n",
       "The         [1.18, -2.312, 1.844, 0.582, -1.1875, 0.957, 0...   \n",
       "University  [1.57, 3.094, -7.562, 4.875, -0.02734, 0.1953,...   \n",
       "of          [0.295, 5.188, -5.125, 2.312, -0.535, -2.234, ...   \n",
       "Virginia    [4.78, -0.01074, -4.156, -2.375, 4.812, 1.07, ...   \n",
       "is          [-2.594, 2.156, -5.5, 4.562, 8.375, 1.695, 0.1...   \n",
       "located     [0.9336, -3.438, -1.516, 0.3555, -0.1211, -1.7...   \n",
       "in          [2.11, -3.312, 4.688, 7.812, 2.703, -1.211, -4...   \n",
       "the         [2.656, -5.656, 3.594, -0.871, 2.703, -5.25, -...   \n",
       "city        [-2.11, -0.914, -5.344, 0.291, 2.812, -5.0, -3...   \n",
       "of          [4.75, -4.812, 6.062, 10.25, 3.156, -2.906, -4...   \n",
       "\n",
       "                                                     layer 28  \\\n",
       "The         [0.9453, -2.172, 1.602, 0.1797, -1.219, 0.664,...   \n",
       "University  [-0.0625, 3.312, -8.56, 6.688, -0.4805, 1.266,...   \n",
       "of          [-0.1875, 3.719, -5.47, 2.062, -1.148, -2.36, ...   \n",
       "Virginia    [3.562, -0.8125, -6.0, -0.9062, 3.578, 1.117, ...   \n",
       "is          [-3.61, 2.0, -8.125, 5.062, 8.69, 2.5, -1.094,...   \n",
       "located     [-0.824, -0.953, -1.969, 0.789, 0.1001, -1.703...   \n",
       "in          [0.4688, -4.75, 4.344, 8.19, 2.547, -2.656, -6...   \n",
       "the         [3.5, -5.812, 2.062, -1.094, 2.0, -4.375, -8.1...   \n",
       "city        [-1.672, -0.379, -4.875, -0.1914, 3.453, -4.78...   \n",
       "of          [3.36, -5.938, 5.75, 11.56, 2.062, -3.016, -5....   \n",
       "\n",
       "                                                     layer 29  \\\n",
       "The         [1.445, -2.516, 2.5, 0.2832, -1.633, 0.3867, 0...   \n",
       "University  [-0.3066, 1.078, -7.03, 7.094, -0.1895, 0.2578...   \n",
       "of          [1.3125, 3.625, -5.25, 3.266, 0.3672, -4.188, ...   \n",
       "Virginia    [4.625, -0.01074, -5.438, -1.398, 2.75, -0.240...   \n",
       "is          [-3.375, 3.828, -8.19, 5.312, 8.81, 2.578, -4....   \n",
       "located     [-2.156, -1.469, -1.461, 1.797, 1.1875, -1.023...   \n",
       "in          [0.7656, -4.22, 7.156, 8.94, 3.062, -4.5, -12....   \n",
       "the         [4.344, -3.016, 2.188, -2.453, 0.0547, -2.438,...   \n",
       "city        [-3.312, -0.633, -5.438, -1.07, 1.9375, -4.0, ...   \n",
       "of          [3.36, -5.188, 7.938, 11.31, 2.719, -5.938, -1...   \n",
       "\n",
       "                                                     layer 30  \\\n",
       "The         [1.016, -0.75, 0.711, -1.094, 0.2422, 0.1309, ...   \n",
       "University  [-0.5195, 2.062, -5.78, 7.406, -1.086, 1.078, ...   \n",
       "of          [1.508, 4.688, -4.03, 5.188, -0.1758, -2.766, ...   \n",
       "Virginia    [6.375, -0.007812, -6.03, -3.25, 2.094, 0.0468...   \n",
       "is          [-1.836, 5.25, -10.56, 5.562, 8.31, 4.125, -1....   \n",
       "located     [-2.406, 1.5625, -0.9297, 0.1094, 1.047, -1.28...   \n",
       "in          [0.789, -5.156, 9.44, 9.69, 2.078, -3.312, -11...   \n",
       "the         [6.312, -0.8047, 2.812, -2.438, -1.4375, -2.73...   \n",
       "city        [-1.625, 0.7227, -6.156, -0.06055, 2.734, -1.1...   \n",
       "of          [3.062, -6.312, 10.625, 11.69, 1.93, -5.688, -...   \n",
       "\n",
       "                                                     layer 31  \\\n",
       "The         [1.32, -0.879, 1.953, -0.711, -0.7734, 0.1289,...   \n",
       "University  [-1.055, 2.938, -5.97, 7.875, 0.5703, 2.672, -...   \n",
       "of          [0.7617, 4.688, -1.719, 4.72, -0.463, -1.945, ...   \n",
       "Virginia    [6.344, 2.375, -6.344, -3.312, 2.922, 1.297, -...   \n",
       "is          [-1.766, 8.06, -9.56, 6.812, 8.19, 4.938, -3.2...   \n",
       "located     [-4.375, 3.688, -0.617, 4.125, -0.2812, 1.891,...   \n",
       "in          [2.203, -3.594, 8.94, 10.125, 2.812, -1.477, -...   \n",
       "the         [7.375, -2.25, 4.03, -0.953, 1.992, -1.445, -9...   \n",
       "city        [-1.047, -0.6914, -5.375, 3.156, 3.938, 0.1484...   \n",
       "of          [4.312, -5.812, 9.69, 12.19, 3.484, -5.125, -1...   \n",
       "\n",
       "                                                     layer 32  \n",
       "The         [-0.3477, 0.3184, -0.1426, -0.0996, 0.3828, -0...  \n",
       "University  [-0.5195, 0.832, -1.094, 2.375, 0.4434, 0.715,...  \n",
       "of          [-0.4727, 0.9688, -0.3203, 0.9688, 0.59, -0.10...  \n",
       "Virginia    [0.3965, 1.039, -0.6836, -0.2617, 0.9844, 0.30...  \n",
       "is          [-0.668, 2.36, -1.227, 1.469, 2.0, 1.133, -1.0...  \n",
       "located     [-1.156, 1.586, -0.2148, 1.586, 0.789, 1.156, ...  \n",
       "in          [0.00958, -0.004883, 1.258, 2.125, 1.258, 0.57...  \n",
       "the         [0.793, 0.4043, 0.5938, 0.867, 1.43, 0.1963, -...  \n",
       "city        [-0.7383, 0.547, -0.824, 1.164, 1.625, 0.498, ...  \n",
       "of          [0.9062, -1.289, 1.8125, 3.031, 1.156, -0.2793...  \n",
       "\n",
       "[10 rows x 32 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    " \n",
    "messages = \"The Space Needle is located in downtown\"\n",
    "messages = \"The University of Virginia is located in the city of\"\n",
    "max_new_tokens = 1\n",
    "\n",
    "pipe = CustomPipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "generation_args = {\n",
    "    \"max_new_tokens\": max_new_tokens,\n",
    "    \"return_full_text\": False,\n",
    "    \"temperature\": 0.0,\n",
    "    \"output_hidden_states\": True,\n",
    "}\n",
    "\n",
    "output = pipe(messages, **generation_args)\n",
    "\n",
    "tokenized_input = output[1]['tokens'][:-max_new_tokens]\n",
    "generated_text = output[0]['generated_text']\n",
    "tokenized_output = output[1]['tokens']\n",
    "hidden_states = output[2][\"hidden_states\"]\n",
    "\n",
    "print(\"Tokenized Input: \", tokenized_input)\n",
    "print(\"Tokenized Output: \", tokenized_output)\n",
    "\n",
    "# visualize the hidden states. This data will be used for the Bayesian Network\n",
    "df = pd.DataFrame(hidden_states)\n",
    "df.columns = ['layer {}'.format(i+1) for i in range(df.shape[1])]\n",
    "df.index = [tokenized_input]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig_width = 90  \n",
    "fig_height = 3\n",
    "\n",
    "# Create a single figure and set the size\n",
    "fig, axes = plt.subplots(nrows=len(hidden_states), ncols=len(hidden_states[0]), figsize=(fig_width, fig_height*len(hidden_states)))\n",
    "\n",
    "# Iterate through each row of hidden_states\n",
    "for i, (row_data, ylabel) in enumerate(zip(hidden_states, tokenized_input)):\n",
    "    # Set y-label for the entire row\n",
    "    axes[i, 0].set_ylabel(ylabel, color=\"red\", fontsize=50)\n",
    "\n",
    "    # Iterate through each entry in the row\n",
    "    for j, entry in enumerate(row_data):\n",
    "        # Plot scatter plot in the corresponding subplot\n",
    "        axes[i, j].scatter(range(len(entry)), entry, alpha=0.6)\n",
    "        if i == 0:\n",
    "            axes[i, j].set_title(f\"Layer {j+1}\")\n",
    "\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(\"scatter_plots.png\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Estimation using Bayesian Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.estimators import MaximumLikelihoodEstimator, BayesianEstimator\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# define BN\n",
    "network = [('A', 'C'), ('B', 'C')]\n",
    "model = BayesianNetwork(network)\n",
    "G = nx.DiGraph(network)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "nx.draw(G, with_labels=True, node_color='skyblue', node_size=2000, font_size=15, font_color='darkred', arrowstyle='-|>', arrowsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B  C\n",
       "0  0  0  1\n",
       "1  0  1  1\n",
       "2  1  0  0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data for parameter estimation\n",
    "data = pd.DataFrame(data={'A': [0, 0, 1], 'B': [0, 1, 0], 'C': [1, 1, 0]})\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "| A(0) | 0.666667 |\n",
      "+------+----------+\n",
      "| A(1) | 0.333333 |\n",
      "+------+----------+\n",
      "+------+------+------+------+------+\n",
      "| A    | A(0) | A(0) | A(1) | A(1) |\n",
      "+------+------+------+------+------+\n",
      "| B    | B(0) | B(1) | B(0) | B(1) |\n",
      "+------+------+------+------+------+\n",
      "| C(0) | 0.0  | 0.0  | 1.0  | 0.5  |\n",
      "+------+------+------+------+------+\n",
      "| C(1) | 1.0  | 1.0  | 0.0  | 0.5  |\n",
      "+------+------+------+------+------+\n"
     ]
    }
   ],
   "source": [
    "estimator = MaximumLikelihoodEstimator(model, data)\n",
    "cpd_A = estimator.estimate_cpd('A')\n",
    "print(cpd_A)\n",
    "cpd_C = estimator.estimate_cpd('C')\n",
    "print(cpd_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bayesian Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+------+--------------------+\n",
      "| A    | A(0) | A(0) | A(1) | A(1)               |\n",
      "+------+------+------+------+--------------------+\n",
      "| B    | B(0) | B(1) | B(0) | B(1)               |\n",
      "+------+------+------+------+--------------------+\n",
      "| C(0) | 0.25 | 0.25 | 0.5  | 0.3333333333333333 |\n",
      "+------+------+------+------+--------------------+\n",
      "| C(1) | 0.75 | 0.75 | 0.5  | 0.6666666666666666 |\n",
      "+------+------+------+------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "estimator = BayesianEstimator(model, data)\n",
    "cpd_C = estimator.estimate_cpd('C', prior_type=\"dirichlet\",\n",
    "                               pseudo_counts=[[1, 1, 1, 1],\n",
    "                                              [2, 2, 2, 2]])\n",
    "print(cpd_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
